---
title: "Classificaion for fMRI curves with similar mean, different variation"
# author: "Hyunsung Kim"
date: '2024-04-23'
format: 
  pdf:
    documentclass: scrartcl
    include-in-header:
      - text: |
          \usepackage{kotex}
      - ./preamble.tex
knitr:
  opts_chunk:
    out.width: "80%"
---


```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
knitr::opts_chunk$set(
  echo = FALSE, message = FALSE, warning = FALSE, 
  # cache = T,
  # fig.width = 12, fig.height = 6,
  # out.width = "80%",
  fig.align = "center"
)
# # Set working directory
# knitr::opts_knit$set(root.dir = "../")
```

# Wavelet

- Fourier와 달리 local하게도 fitting이 가능
  - Fourier transform을 특정 길이의 window를 도입하여 local하게 하는 방법인 STFT (Short-Time Fourier Transform)도 있으나 low frequency를 잘 잡아내지 못하는 단점이 존재
  - Wavelet의 경우는 이러한 단점이 보완된 방법이라고 알려져있음

### 문제점
- timepoint가 $2^M$ 형태의 개수를 가져야 제대로 구현됨
- signal filter를 하나씩 적용해가면서 coefficient를 찾는데, noise를 제거하는 smoothing 관점에서는 적합해보이나 차원축소 관점에서는 적절치 않아보임
- 그림과 같이 1개 curve에 대해 DWT (Discrete Wavelet Transform)를 적용하였을 때, 각 filter와 timepoint마다의 coefficient가 존재하게 됨
  - 즉, 1개 curve에 coefficient가 $(\# ~of~ filters) \times (\# ~of~ timepoints)$가 되어 차원축소 관점에서 적절하지 않아보임



```{r}
# 191 curves from 1st region
idx <- 75
file_list <- list.files("./fMRI_Classification/AlignedSubject/")
df <- read.csv(paste0("./fMRI_Classification/AlignedSubject/", file_list[1]), header = T)
X <- as.numeric(unlist(df[idx, -1]))

library(wavelets)
newX <- X
wt <- dwt(newX, filter = "d8")
invX <- idwt(wt)
# plot(newX, type = "l")
# lines(invX, col = 2)
# sum(newX - invX )
plot(wt)
```


\newpage

# 75th region에서의 결과

- 다음의 비교 방법론 고려
  - `Fused`: Baek, S., Kim, Y., Park, J., & Lee, J. S. (2022). Revisit to functional data analysis of sleeping energy expenditure. Journal of Applied Statistics, 49(4), 988-1002.
    - 현재 knots 개수 = 30, penalty parameters grid search
      - knots 개수의 경우 cross-validation할 경우, candidate중 최대값만 선택되어 30개로 fixed함
  - `VPC`: Jiao, S., Frostig, R. D., & Ombao, H. (2023). Variation pattern classification of functional data. Canadian Journal of Statistics, 51(4), 943-958.
    - feature function 개수는 PVE $\ge 0.90$ rule 적용
  - `FGLM`: Functional generalized linear model (logistic)
    - 내부적으로 B-spline basis expansion을 적용 (7 basis functions)
  - `Eig`: Covariance fuction의 first 5 eigenvalues의 합을 기준으로 prediction
    - training set에서 각 class별 eigenvalue를 계산하고, test 데이터를 포함한 상태에서 구한 eigenvalue와의 차이가 적은 쪽으로 classification

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & Fused & VPC & FGLM & Eig \\ 
  \hline
  Accuracy & 0.543 & 0.447 & 0.592 & 0.556  \\ 
  \hline
\end{tabular}
\end{table}


