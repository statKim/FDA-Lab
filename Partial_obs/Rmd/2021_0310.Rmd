---
title: "Partially observed functional data"
author: "Hyunsung Kim"
date: '2021-03-10'
output: 
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    fig_caption: true
    # number_sections: true
    toc: true
    # toc_depth: 2
# header-includes:
#   - \newcommand{\argmin}{\mathop{\mathrm{argmin}}\limits}
---

<style>
  p.caption {   <!-- figure caption -->
    font-size: 0.9em;
    font-style: italic;
    color: grey;
    <!-- margin-right: 10%; -->
    <!-- margin-left: 10%;   -->
    text-align: justify;
  }
  caption {    <!-- table caption -->
    font-size: 0.9em;
    font-style: italic;
    color: grey;
    <!-- margin-right: 10%; -->
    <!-- margin-left: 10%;   -->
    text-align: justify;
  }
</style>


```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, 
                      # cache = T,
                      fig.align = "center", fig.width = 12, fig.height = 6)
# Set working directory
knitr::opts_knit$set(root.dir = "../")
```

# ```{r}
# library(GA)   # persp plot
# library(mvtnorm)
# library(fdapace)   # 1, 2
# library(mcfda)   # 7
# library(synfd)   # 7
# library(doParallel)   # parallel computing
# library(doRNG)   # set.seed for foreach
# library(MASS)   # huber, rlm
# source("functions.R")
# library(kableExtra)
# library(tidyverse)
# library(gridExtra)
# library(latex2exp)
# source("utills.R")
# ```


# Iteratively re-weighted least squares (IRLS; IRWLS)

## IRLS for robust regression
- Our objective is to find $\hat{\beta} = \arg\min_{\beta} \sum_{i=1}^n \rho \left( \frac{y_i - x_i^T\beta}{s} \right)$, and let $L = \sum_{i=1}^n \rho \left( \frac{y_i - x_i^T\beta}{s} \right).$
- Then a normal equation could be found by applying 1st derivative : 
  $$
  \frac{\partial L}{\partial \beta} = \sum_{i=1}^n x_i \psi \left( \frac{y_i - x_i^T\beta}{s} \right) = 0, \text{ where } \psi(x) = \rho'(x)
  $$
- Set $w_i = \psi \left( \frac{y_i - x_i^T\beta}{s} \right) / \left( y_i - x_i^T\beta \right).$
- Then a normal equation be as 
  $$
  \sum_{i=1}^n x_iw_i(y_i - x_i^T\beta) = 0 \\
  \Leftrightarrow X^TWY-XWX^T\beta=0 
  $$
- Therefore, the solution can be obtained by weighted least squares as 
  $$ \hat{\beta} = (X^TWX)^{-1}X^TWY $$
- The above equation can be solved by following **Iteratively re-weighted least squares (IRLS) algorithm**.


### IRLS algorithm
1. Set initial value $\hat{\beta}^{(0)}$, then we can compute $W^{(0)}$.
2.  Therefore, $\hat{\beta}^{(1)}$ for 1st iterations can be obtained as
  $$
  \hat{\beta}^{(1)} = (X^TW^{(0)}X)^{-1}X^TW^{(0)}Y.
  $$
3. Similarly, $\hat{\beta}^{(t+1)}$ for $t$th iterations can be represented as
  $$
  \hat{\beta}^{(t+1)} = (X^TW^{(t)}X)^{-1}X^TW^{(t)}Y.
  $$
4. Repeat this procedure until $\hat{\beta}^{(t)}$ is converged.

<br>


## IRLS for local kernel smoother with Huber loss
$$
\begin{align}
  (\hat{b}_0, \hat{b}_1) &= \underset{(b_0,b_1) \in \mathbb{R}^2}{\operatorname{\arg\min}} \sum_{i=1}^n w_i \sum_{j=1}^{m_i} K_{h_{\mu}} (T_{ij}-t) \rho \left\{ Y_{ij} - b_0 - b_1(T_{ij}-t) \right\} , \\
  (\hat{b}_0, \hat{b}_1) &= \underset{(b_0,b_1) \in \mathbb{R}^2}{\operatorname{\arg\min}} \sum_{i=1}^n w_i \sum_{j=1}^{m_i} K_{h_{\sigma}} (T_{ij}-t) \rho \left[ \{Y_{ij} - \hat{\mu}(T_{ij})\}^2 - b_0 - b_1(T_{ij}-t) \right],
\end{align}
$$

- Vectorise $\left( p = 1, \dots, P=\sum_{i=1}^n m_i \right)$ and let weight $K_p = w_i K_{h_{\mu}} (T_{ij}-t)$.
- Let $L = \sum_{p=1}^P K_p \rho \left( \frac{y_p - x_p^T\beta}{s} \right)$, then we could find the solution $\hat{\beta} = \arg\min_{\beta} L$.
- Normal equation :
  $$
  \frac{\partial L}{\partial \beta} = \sum_{p=1}^P K_p x_p \psi \left( \frac{y_p - x_p^T\beta}{s} \right) = 0
  $$
- Set $w_p = \left\{ K_p \psi \left( \frac{y_p - x_p^T\beta}{s} \right) \right\} / \left( y_p - x_p^T\beta \right).$
- Apply **IRLS algorithm** until $\hat{\beta}$ is converged.


<br>

# Selection $\delta$ for Huber loss
## Naive method
$$
  \delta = 1 / \max\left\{ Y_{ij} : i = 1,\dots,n, j = 1,\dots,m_i \right\}
$$
## Cross-validation
