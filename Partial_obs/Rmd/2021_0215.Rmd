---
title: "Partially observed functional data"
author: "Hyunsung Kim"
date: '2021-02-15'
output: 
  prettydoc::html_pretty:
    # theme: leonids
    # theme: hpstr
    theme: cayman
    highlight: github
    fig_caption: true
    # number_sections: true
    toc: true
    # toc_depth: 2
---

<style>
  p.caption {   <!-- figure caption -->
    font-size: 0.9em;
    font-style: italic;
    color: grey;
    <!-- margin-right: 10%; -->
    <!-- margin-left: 10%;   -->
    text-align: justify;
  }
  caption {    <!-- table caption -->
    font-size: 0.9em;
    font-style: italic;
    color: grey;
    <!-- margin-right: 10%; -->
    <!-- margin-left: 10%;   -->
    text-align: justify;
  }
</style>


```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, 
                      # cache = T,
                      fig.align = "center", fig.width = 12, fig.height = 6)
# Set working directory
knitr::opts_knit$set(root.dir = "../")
```

```{r}
library(GA)   # persp plot
library(mvtnorm)
library(fdapace)   # 1, 2
library(mcfda)   # 7
library(synfd)   # 7
library(doParallel)   # parallel computing
library(doRNG)   # set.seed for foreach
source("functions.R")
library(kableExtra)
library(tidyverse)
library(latex2exp)
library(gridExtra)
```


<br>

# PCA Results for Simulation 2
- Simulation 2에서는 true covariance를 알고 있기 때문에 이를 spectral decomposition한 eigenvector와 generate한 데이터로부터 추정된 covariance로부터의 eigenvector의 ISE를 비교

## Estimated first 3 eigenfunctions
```{r fig, fig.cap = "Figure 1. Estimated first 3 eigenfunctions for 1st simulation data.", fig.height = 16}
p <- list()

### Without outliers
k <- 1
fname <- paste0("RData/sim3-", k, "_20210204.RData")
load(fname)

sim <- 1
for (i in 1:3) {
  if (i == 1) {
    p_title <- "Outlier X"
  } else {
    p_title <- ""
  }
  
  # estimated covariances from Simulation 3
  work.grid <- cov.est[[sim]]$work.grid
  cov.true <- cov.est[[sim]]$cov$true
  cov.yao <- cov.est[[sim]]$cov$yao
  cov.lin <- cov.est[[sim]]$cov$lin
  
  # eigen analysis
  eig.true <- get_eigen(cov = cov.true, grid = work.grid)
  eig.yao <- get_eigen(cov = cov.yao, grid = work.grid)
  eig.lin <- get_eigen(cov = cov.lin, grid = work.grid)
  
  # k <- length(which(eig.true$PVE < 0.99))
  
  fig.data <- data.frame(work.grid = rep(work.grid, 3),
                         phi = c(eig.true$phi[, i],
                                 eig.yao$phi[, i],
                                 eig.lin$phi[, i]),
                         method = rep(c("True","Yao(2005)","Lin(2020)"), each = length(work.grid)))
  p[[i]] <- ggplot(data = fig.data, 
                   mapping = aes(work.grid, phi, color = method)) +
    geom_line(size = 1) +
    labs(x = TeX("$t$"), y = TeX(paste0("$\\phi_", i, "(t)$")), title = p_title) +
    scale_color_discrete(breaks = c("True","Yao(2005)","Lin(2020)")) +
    theme_bw() +
    theme(legend.title = element_blank(),
          legend.position = "bottom")
}

### With outliers
for (k in 1:3) {
  fname <- paste0("RData/sim3-", k, "_20210204.RData")
  load(fname)
  
  # remove list contating "null"  
  ind <- which(!sapply(cov.est.outlier, is.null))
  cov.est.outlier <- cov.est.outlier[ind]

  sim <- 1
  for (i in 1:3) {
    if (i == 1) {
      p_title <- paste("Outlier", k)
    } else {
      p_title <- ""
    }
    
    # estimated covariances from Simulation 3
    work.grid <- cov.est.outlier[[sim]]$work.grid
    cov.true <- cov.est.outlier[[sim]]$cov$true
    cov.yao <- cov.est.outlier[[sim]]$cov$yao
    cov.lin <- cov.est.outlier[[sim]]$cov$lin
    
    # eigen analysis
    eig.true <- get_eigen(cov = cov.true, grid = work.grid)
    eig.yao <- get_eigen(cov = cov.yao, grid = work.grid)
    eig.lin <- get_eigen(cov = cov.lin, grid = work.grid)
    
    # k <- length(which(eig.true$PVE < 0.99))
    
    fig.data <- data.frame(work.grid = rep(work.grid, 3),
                           phi = c(eig.true$phi[, i],
                                   eig.yao$phi[, i],
                                   eig.lin$phi[, i]),
                           method = rep(c("True","Yao(2005)","Lin(2020)"), each = length(work.grid)))
    p[[3*k+i]] <- ggplot(data = fig.data, 
                         mapping = aes(work.grid, phi, color = method)) +
      geom_line(size = 1) +
      labs(x = TeX("$t$"), y = TeX(paste0("$\\phi_", i, "(t)$")), title = p_title) +
      scale_color_discrete(breaks = c("True","Yao(2005)","Lin(2020)")) +
      theme_bw() +
      theme(legend.title = element_blank(),
            legend.position = "bottom")
  }
}

grid.arrange(grobs = p,   # mget(): get multiple objects
             nrow = 4)
```


## MISE for first 3 eigenfunctions
```{r tab1}
# Parallel computing setting
ncores <- detectCores() - 3
cl <- makeCluster(ncores)
registerDoParallel(cl)

res <- list()

### Eigen analysis
for (k in 1:3) {
  fname <- paste0("RData/sim3-", k, "_20210204.RData")
  load(fname)
  
  ## original model
  if (k == 1) {
    # remove list contating "null"  
    ind <- which(!sapply(cov.est, is.null))
    cov.est <- cov.est[ind]
    num.sim <- length(ind)
    
    res[[k]] <- sim_eigen_result(cov.est, num.sim, seed = 1000)
  }
  
  ## outlier model
  # remove list contating "null"  
  ind <- which(!sapply(cov.est.outlier, is.null))
  cov.est.outlier <- cov.est.outlier[ind]
  num.sim <- length(ind)
  
  res[[k+1]] <- sim_eigen_result(cov.est.outlier, num.sim, seed = 1000)
}
stopCluster(cl)  

### Calculate ISE for 1~3 eigenfunctions
cname <- c("Yao (2005)","Lin (2020)")
res.mat <- matrix(NA, 4, 3)
colnames(res.mat) <- c("$N$", cname)
row.names(res.mat) <- c("Outlier X",
                        paste0("Outlier ", 1:3))

for (j in 1:4) {
  pca.est <- res[[j]]
  num.sim <- length(pca.est)
  ise <- matrix(NA, num.sim, 2)
  
  for (i in 1:num.sim) {
    work.grid <- pca.est[[i]]$work.grid
    
    eig.true <- pca.est[[i]]$true
    eig.yao <- pca.est[[i]]$yao
    eig.lin <- pca.est[[i]]$lin
    
    # K <- length(which(eig.true$PVE < 0.99))
    K <- 3
    
    # calculate ISE for k eigenfunctions
    ise_eig <- matrix(NA, K, 2)
    for (k in 1:K) {
      ise_eig[k, ] <- c(
        get_ise(eig.true$phi[, k], eig.yao$phi[, k], work.grid),
        get_ise(eig.true$phi[, k], eig.lin$phi[, k], work.grid)
      )
    }
    
    ise[i, ] <- colSums(ise_eig)
  }
  
  res.mat[j, ] <- c(
    num.sim,
    paste0(round(sqrt(colMeans(ise)), 2), 
           "(", 
           round(apply(ise, 2, sd), 2), 
           ")")
  )
}

knitr::kable(res.mat, digits = 3, align = "r", caption = "Table 1. Average MISE (standard error) of first 3 eigenfunctions.") %>% 
  kable_styling("striped", full_width = FALSE, font_size = 14)
```