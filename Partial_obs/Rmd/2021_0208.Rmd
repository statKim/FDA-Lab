---
title: "Partially observed functional data"
author: "Hyunsung Kim"
date: '2021-02-08'
output: 
  prettydoc::html_pretty:
    # theme: leonids
    # theme: hpstr
    theme: cayman
    highlight: github
    fig_caption: true
    # number_sections: true
    toc: true
    # toc_depth: 2
---

<style>
  p.caption {   <!-- figure caption -->
    font-size: 0.9em;
    font-style: italic;
    color: grey;
    <!-- margin-right: 10%; -->
    <!-- margin-left: 10%;   -->
    text-align: justify;
  }
  caption {    <!-- table caption -->
    font-size: 0.9em;
    font-style: italic;
    color: grey;
    <!-- margin-right: 10%; -->
    <!-- margin-left: 10%;   -->
    text-align: justify;
  }
</style>


```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, 
                      # cache = T,
                      fig.align = "center", fig.width = 12, fig.height = 6)
# Set working directory
knitr::opts_knit$set(root.dir = "../")
```


```{r}
library(GA)   # persp plot
library(kableExtra)
library(fdapace)   # 1, 2
library(mcfda)   # 7
library(synfd)   # 7
source("functions.R")
source("Kraus(2015)/pred.missfd.R")   # 3
source("Kraus(2015)/simul.missfd.R")  # 3
```


<br>


# Simulation 1

## Simulation settings
> Lin, Z., & Wang, J. L. (2020). Mean and covariance estimation for functional snippets. Journal of the American Statistical Association, 1-13.

- 위 논문의 5장에서 $\text{cov I}, n=200, \delta=0.25, \text{SNR}=2$인 경우를 활용하였으며, $N=100$번 반복시행
- 기존 모형과 outlier를 추가하였을 때의 차이를 확인 (outlier 비율은 0.2라 가정)
- Variance $\sigma_X^2$과 covariance $C$의 estimation performance를 비교


## Outliers settings
- **Outlier 1~3**
  - Outlier는 wiener process로부터 생성 후 mean function을 더해줌 (기존은 gaussian process)
  - 3가지 mean function에 따라 결과 확인 (기존은 $\mu(t) = 2t^2\cos(2\pi t)$)
    - $\mu_1(t) = -2t^2 \cos(2\pi t)$ ($y$축 기준으로 대칭인 형태)
    - $\mu_2(t) = -3\sin(4\pi t)$ (fluctuation이 다른 형태)
    - $\mu_3(t) = 2(t-0.2)^2\cos(2\pi(t-0.2))$ ($x$축으로 평행이동한 형태)
- **Outlier 4~6**
```{r out_sim1, out.width = "100%"}
file_name <- paste0(getwd(), "/ref/outlier_ex.png")
knitr::include_graphics(file_name)
```

## Original model

```{r fig1, fig.cap = "Figure 1. Design plot (Left) and sample trajectories with mean curve (Right)."}
### load files
fname <- "RData/20210125_1.RData"
load(fname)
outlier.ratio <- 0.2   # ratio of outliers
n <- 200   # number of curves
n.outlier <- ceiling(n*outlier.ratio)

#############################
### Visualization
#############################
i <- 1
x <- data.list[[i]]$x

### Design plot and sample trajectories
par(mfrow = c(1, 2))
CreateDesignPlot(x$t, main = "")
plot(x$t[[1]], x$y[[1]], type = "l", col="grey",
     xlim = range(unlist(x$t)), ylim = range(unlist(x$y)), xlab = "Time", ylab = "")
for (j in 2:n) {
  lines(x$t[[j]], x$y[[j]], col = "grey")
}
mu <- function(s) { 2*(s^2)*cos(2*pi*s) }   # true mean
gr <- cov.est[[i]]$mu.obj$yao$workGrid
lines(gr, mu(gr), col = 2, lwd = 2)
with(cov.est[[i]]$mu.obj$yao, lines(workGrid, mu, lwd = 2, col = 4))   # estimated mean curve
legend("topleft", c("True mean","Estimated mean"), col = c(2,4), lty = c(1,1))
```


## Outliers

```{r fig2, fig.cap = "Figure 2. Sample trajectories with outliers and estimated mean curves.", fig.height = 8}
par(mfrow = c(2, 3))
for (k in 1:6) {
  if (k <= 3) {
    fname <- paste("RData/20210125_", k, ".RData", sep = "")
  } else {
    fname <- paste("RData/20210127_", k-3, ".RData", sep = "")
  }
  load(fname)
  
  # remove list contating "null"  
  ind <- which(!sapply(cov.est.outlier, is.null))
  data.list.outlier <- data.list.outlier[ind]
  cov.est.outlier <- cov.est.outlier[ind]
  
  #############################
  ### Visualization with outliers
  #############################
  i <- 1
  x <- data.list.outlier[[i]]$x
  
  ### Design plot and sample trajectories
  # if (k == 1) {
  #   CreateDesignPlot(x$t, main = "")
  # }
  
  plot(x$t[[1]], x$y[[1]], type = "l", col = "grey",
       main = paste("Outlier", k),
       xlim = range(unlist(x$t)), ylim = range(unlist(x$y)), xlab = "Time", ylab = "")
  for (j in 2:n) {
    if (j > n-n.outlier) {
      lines(x$t[[j]], x$y[[j]], col = 1)
    } else {
      lines(x$t[[j]], x$y[[j]], col = "grey")
    }
  }
  mu <- function(s) { 2*(s^2)*cos(2*pi*s) }   # true mean
  gr <- cov.est.outlier[[i]]$mu.obj$yao$workGrid
  lines(gr, mu(gr), col = 2, lwd = 2)
  with(cov.est.outlier[[i]]$mu.obj$yao, lines(workGrid, mu, lwd = 2, col = 4))   # estimated mean curve
  legend("topleft", c("True mean","Estimated mean"), col = c(2,4), lty = c(1,1))
}
```

```{r fig3, fig.cap = "Figure 3. True covariance surface and estimated covariance surfaces.", fig.height = 14, fig.width = 8}
i <- 1
par(mfrow = c(7, 3),
    mar = c(2, 2, 2, 2))
for (k in 1:6) {
  if (k <= 3) {
    fname <- paste("RData/20210125_", k, ".RData", sep = "")
  } else {
    fname <- paste("RData/20210127_", k-3, ".RData", sep = "")
  }
  load(fname)
  
  # remove list contating "null"  
  ind <- which(!sapply(cov.est.outlier, is.null))
  data.list.outlier <- data.list.outlier[ind]
  cov.est.outlier <- cov.est.outlier[ind]
  
  if (k == 1) {
    main <- c("True","Yao et al. (2005)","Lin & Wang (2020)")
    
    ### Covariance surface
    work.grid <- cov.est[[i]]$work.grid
    cov.list <- cov.est[[i]]$cov
    
    # par(mfrow = c(1, 3),
    #     mar = c(0, 2, 7, 2))
    persp3D(work.grid, work.grid, cov.list$true, 
            theta = -70, phi = 30, expand = 1,
            main = main[1], 
            xlab = "s", ylab = "t", zlab = "C(s,t)")
    mtext("Outlier X", side = 2)
    persp3D(work.grid, work.grid, cov.list$yao, 
            theta = -70, phi = 30, expand = 1,
            main = main[2], 
            xlab = "s", ylab = "t", zlab = "C(s,t)")
    persp3D(work.grid, work.grid, cov.list$lin, 
            theta = -70, phi = 30, expand = 1,
            main = main[3],
            xlab = "s", ylab = "t", zlab = "C(s,t)")
  }
    
  main <- c("","","")
  
  ### Covariance surface
  work.grid <- cov.est.outlier[[i]]$work.grid
  cov.list <- cov.est.outlier[[i]]$cov
  # par(mfrow = c(1, 3),
  #     mar = c(0, 2, 7, 2))
  persp3D(work.grid, work.grid, cov.list$true, 
          theta = -70, phi = 30, expand = 1,
          main = main[1], 
          xlab = "s", ylab = "t", zlab = "C(s,t)")
  mtext(paste("Outlier", k), side = 2)
  persp3D(work.grid, work.grid, cov.list$yao, 
          theta = -70, phi = 30, expand = 1,
          main = main[2], 
          xlab = "s", ylab = "t", zlab = "C(s,t)")
  persp3D(work.grid, work.grid, cov.list$lin, 
          theta = -70, phi = 30, expand = 1,
          main = main[3],
          xlab = "s", ylab = "t", zlab = "C(s,t)")
}
```


```{r tab1}
cname <- c("Yao (2005)","Lin (2020)")
res.mat <- matrix(NA, 7, 5)
colnames(res.mat) <- c("$N$", cname, cname)
row.names(res.mat) <- c("Outlier X",
                        paste0("Outlier ", 1:6))

for (k in 1:6) {
  if (k <= 3) {
    fname <- paste("RData/20210125_", k, ".RData", sep = "")
  } else {
    fname <- paste("RData/20210127_", k-3, ".RData", sep = "")
  }
  load(fname)
  
  # remove list contating "null"  
  ind <- which(!sapply(cov.est.outlier, is.null))
  num.sim <- length(ind)   # number of simulations
  data.list.outlier <- data.list.outlier[ind]
  cov.est.outlier <- cov.est.outlier[ind]
  
  #############################
  ### Calculate RMISE with outliers
  #############################
  ### variance
  ise.var <- summary_ise(data.list.outlier, cov.est.outlier, method = "var")
  ### covariance
  ise.cov <- summary_ise(data.list.outlier, cov.est.outlier, method = "cov")
  
  # res.mat[k+1, ] <- c(num.sim,
  #                     sqrt(rowMeans(ise.var)),
  #                     sqrt(rowMeans(ise.cov)))
  res.mat[k+1, ] <- c(num.sim,
                      paste0(round(sqrt(rowMeans(ise.var)), 2), 
                             "(", 
                             round(apply(ise.var, 1, sd), 2), 
                             ")"),
                      paste0(round(sqrt(rowMeans(ise.cov)), 2), 
                             "(", 
                             round(apply(ise.cov, 1, sd), 2), 
                             ")"))
  
  if (k == 1) {
    ### variance
    ise.var <- summary_ise(data.list, cov.est, method = "var")
    ### covariance
    ise.cov <- summary_ise(data.list, cov.est, method = "cov")
    
    # res.mat[k, ] <- c(num.sim,
    #                   sqrt(rowMeans(ise.var)),
    #                   sqrt(rowMeans(ise.cov)))
    res.mat[k, ] <- c(num.sim,
                      paste0(round(sqrt(rowMeans(ise.var)), 2), 
                             "(", 
                             round(apply(ise.var, 1, sd), 2), 
                             ")"),
                      paste0(round(sqrt(rowMeans(ise.cov)), 2), 
                             "(", 
                             round(apply(ise.cov, 1, sd), 2), 
                             ")"))
  }
}

knitr::kable(res.mat, digits = 3, align = "r", caption = "Table 1. Average RMISE (standard error) of variances($\\hat{\\sigma}_X^2$) and covariances($\\hat{\\mathbf{C}}$) estimation.") %>% 
    kable_styling("striped", full_width = FALSE, font_size = 14) %>% 
    add_header_above(c(" " = 1, " " = 1, "$\\hat{\\sigma}_X^2$" = 2, "$\\hat{\\mathbf{C}}$" = 2))
```

```{r tab_Lin, out.width = "100%"}
file_name <- paste0(getwd(), "/ref/paper_tab_Lin.png")
knitr::include_graphics(file_name)
```


<br>

# Simulation 2

## Simulation settings
> Delaigle, A., Hall, P., Huang, W., & Kneip, A. (2020). Estimating the Covariance of Fragmented and Other Related Types of Functional Data. Journal of the American Statistical Association, 1-19.

- 위 논문의 5장에서 Model 2, $n=100$인 경우 활용하였으며, $N=100$번 반복시행
- 기존 모형과 outlier를 추가하였을 때의 차이를 확인 (outlier 비율은 0.2라 가정)
- Variance $\sigma_X^2$과 covariance $C$의 estimation performance를 비교
- Covariance의 intrapolation($\mathcal{D}_0$)과 extrapolation($\mathcal{S}_0 \backslash \mathcal{D}_0$) parts를 비교


## Outliers settings
- **Outlier 1~3**
```{r out_sim2, out.width = "100%"}
file_name <- paste0(getwd(), "/ref/outlier_ex.png")
knitr::include_graphics(file_name)
```

## Original model

```{r fig4, fig.cap = "Figure 4. Design plot (Left) and sample trajectories with mean curve (Right)."}
### load files
fname <- "RData/sim3-1_20210204.RData"
load(fname)
outlier.ratio <- 0.2   # ratio of outliers
n <- 100   # number of curves
n.outlier <- ceiling(n*outlier.ratio)

#############################
### Visualization
#############################
i <- 1
x <- data.list[[i]]$x

### Design plot and sample trajectories
par(mfrow = c(1, 2))
CreateDesignPlot(x$t, main = "", isColorPlot = FALSE, addLegend = FALSE, noDiagonal = FALSE)
plot(x$t[[1]], x$y[[1]], type = "l", col="grey",
     xlim = range(unlist(x$t)), ylim = range(unlist(x$y)), xlab = "Time", ylab = "")
for (j in 2:n) {
  lines(x$t[[j]], x$y[[j]], col = "grey")
}
mu <- function(s) { 2*(s^2)*cos(2*pi*s) }   # true mean
gr <- cov.est[[i]]$mu.obj$yao$workGrid
lines(gr, mu(gr), col = 2, lwd = 2)
with(cov.est[[i]]$mu.obj$yao, lines(workGrid, mu, lwd = 2, col = 4))   # estimated mean curve
legend("topleft", c("True mean","Estimated mean"), col = c(2,4), lty = c(1,1))
```


## Outliers

```{r fig5, fig.cap = "Figure 5. Sample trajectories with outliers and estimated mean curves.", fig.height = 4}
par(mfrow = c(1, 3))
for (k in 1:3) {
  fname <- paste("RData/sim3-", k, "_20210204.RData", sep = "")
  load(fname)
  cov.est.outlier <- cov.est.outlier[!sapply(cov.est.outlier, is.null)]
  
  #############################
  ### Visualization with outliers
  #############################
  i <- 1
  x <- data.list.outlier[[i]]$x
  
  ### Design plot and sample trajectories
  # if (k == 1) {
  #   CreateDesignPlot(x$t, main = "")
  # }
  
  plot(x$t[[1]], x$y[[1]], type = "l", col = "grey",
       main = paste("Outlier", k),
       xlim = range(unlist(x$t)), ylim = range(unlist(x$y)), xlab = "Time", ylab = "")
  for (j in 2:n) {
    if (j > n-n.outlier) {
      lines(x$t[[j]], x$y[[j]], col = 1)
    } else {
      lines(x$t[[j]], x$y[[j]], col = "grey")
    }
  }
  mu <- function(s) { 2*(s^2)*cos(2*pi*s) }   # true mean
  gr <- cov.est.outlier[[i]]$mu.obj$yao$workGrid
  lines(gr, mu(gr), col = 2, lwd = 2)
  with(cov.est.outlier[[i]]$mu.obj$yao, lines(workGrid, mu, lwd = 2, col = 4))   # estimated mean curve
  legend("topleft", c("True mean","Estimated mean"), col = c(2,4), lty = c(1,1))
}
```


```{r fig6, fig.cap = "Figure 6. True covariance surface and estimated covariance surfaces.", fig.height = 8, fig.width = 8}
i <- 1
par(mfrow = c(4, 3),
    mar = c(2, 2, 2, 2))
for (k in 1:3) {
  fname <- paste("RData/sim3-", k, "_20210204.RData", sep = "")
  load(fname)
  cov.est.outlier <- cov.est.outlier[!sapply(cov.est.outlier, is.null)]
  
  if (k == 1) {
    main <- c("True","Yao et al. (2005)","Lin & Wang (2020)")
    
    ### Covariance surface
    work.grid <- cov.est[[i]]$work.grid
    cov.list <- cov.est[[i]]$cov
    
    # par(mfrow = c(1, 3),
    #     mar = c(0, 2, 7, 2))
    persp3D(work.grid, work.grid, cov.list$true, 
            theta = -40, phi = 30, expand = 1,
            main = main[1], 
            xlab = "s", ylab = "t", zlab = "C(s,t)")
    mtext("Outlier X", side = 2)
    persp3D(work.grid, work.grid, cov.list$yao, 
            theta = -40, phi = 30, expand = 1,
            main = main[2], 
            xlab = "s", ylab = "t", zlab = "C(s,t)")
    persp3D(work.grid, work.grid, cov.list$lin, 
            theta = -40, phi = 30, expand = 1,
            main = main[3],
            xlab = "s", ylab = "t", zlab = "C(s,t)")
  }
    
  main <- c("","","")
  
  ### Covariance surface
  work.grid <- cov.est.outlier[[i]]$work.grid
  cov.list <- cov.est.outlier[[i]]$cov
  # par(mfrow = c(1, 3),
  #     mar = c(0, 2, 7, 2))
  persp3D(work.grid, work.grid, cov.list$true, 
          theta = -40, phi = 30, expand = 1,
          main = main[1], 
          xlab = "s", ylab = "t", zlab = "C(s,t)")
  mtext(paste("Outlier", k), side = 2)
  persp3D(work.grid, work.grid, cov.list$yao, 
          theta = -40, phi = 30, expand = 1,
          main = main[2], 
          xlab = "s", ylab = "t", zlab = "C(s,t)")
  persp3D(work.grid, work.grid, cov.list$lin, 
          theta = -40, phi = 30, expand = 1,
          main = main[3],
          xlab = "s", ylab = "t", zlab = "C(s,t)")
}
```


```{r tab2}
#############################
### Calculate RMISE with outliers
#############################
cname <- c("Yao (2005)","Lin (2020)")
res.mat <- matrix(NA, 4, 5)
colnames(res.mat) <- c("$N$", cname, cname)
row.names(res.mat) <- c("Outlier X",
                        paste0("Outlier ", 1:3))
res.mat2 <- res.mat

for (k in 1:3) {
  fname <- paste("RData/sim3-", k, "_20210204.RData", sep = "")
  load(fname)
  
  # remove list contating "null"  
  ind <- which(!sapply(cov.est.outlier, is.null))
  num.sim <- length(ind)   # number of simulations
  data.list.outlier <- data.list.outlier[ind]
  cov.est.outlier <- cov.est.outlier[ind]
  
  ### variance
  ise.var <- summary_ise(data.list.outlier, cov.est.outlier, method = "var")
  ### covariance
  ise.cov <- summary_ise(data.list.outlier, cov.est.outlier, method = "cov")
  
  # res.mat[k+1, ] <- c(num.sim,
  #                     sqrt(rowMeans(ise.var)),
  #                     sqrt(rowMeans(ise.cov)))
  res.mat[k+1, ] <- c(num.sim,
                      paste0(round(sqrt(rowMeans(ise.var)), 2), 
                             "(", 
                             round(apply(ise.var, 1, sd), 2), 
                             ")"),
                      paste0(round(sqrt(rowMeans(ise.cov)), 2), 
                             "(", 
                             round(apply(ise.cov, 1, sd), 2), 
                             ")"))
  
  
  ### Intrapolation parts (D_0)
  ise.intra <- summary_ise(data.list.outlier, cov.est.outlier, method = "intra")
  ### Extrapolation parts (S_0 \ D_0)
  ise.extra <- summary_ise(data.list.outlier, cov.est.outlier, method = "extra")

  # res.mat2[k+1, ] <- c(num.sim,
  #                      rowMeans(ise.intra),
  #                      rowMeans(ise.extra))
  res.mat2[k+1, ] <- c(num.sim,
                      paste0(round(rowMeans(ise.intra), 2), 
                             "(", 
                             round(apply(ise.intra, 1, sd), 2), 
                             ")"),
                      paste0(round(rowMeans(ise.extra), 2), 
                             "(", 
                             round(apply(ise.extra, 1, sd), 2), 
                             ")"))
  # res.mat2[k+1, 3:4] <- rowMeans(ise.extra)   # ISE
  # ise_sd[2, 3:4] <- apply(ise.cov, 1, sd)


  if (k == 1) {
    # remove list contating "null"  
    ind <- which(!sapply(cov.est, is.null))
    num.sim <- length(ind)   # number of simulations
    data.list <- data.list[ind]
    cov.est <- cov.est[ind]
  
    ### variance
    ise.var <- summary_ise(data.list, cov.est, method = "var")
    ### covariance
    ise.cov <- summary_ise(data.list, cov.est, method = "cov")
    
    # res.mat[k, ] <- c(num.sim,
    #                   sqrt(rowMeans(ise.var)),
    #                   sqrt(rowMeans(ise.cov)))
    res.mat[k, ] <- c(num.sim,
                      paste0(round(sqrt(rowMeans(ise.var)), 2), 
                             "(", 
                             round(apply(ise.var, 1, sd), 2), 
                             ")"),
                      paste0(round(sqrt(rowMeans(ise.cov)), 2), 
                             "(", 
                             round(apply(ise.cov, 1, sd), 2), 
                             ")"))
    
    
    ### Intrapolation parts (D_0)
    ise.intra <- summary_ise(data.list, cov.est, method = "intra")
    ### Extrapolation parts (S_0 \ D_0)
    ise.extra <- summary_ise(data.list, cov.est, method = "extra")
    # res.mat2[k, ] <- c(num.sim,
    #                    rowMeans(ise.intra),
    #                    rowMeans(ise.extra))
    res.mat2[k, ] <- c(num.sim,
                      paste0(round(rowMeans(ise.intra), 2), 
                             "(", 
                             round(apply(ise.intra, 1, sd), 2), 
                             ")"),
                      paste0(round(rowMeans(ise.extra), 2), 
                             "(", 
                             round(apply(ise.extra, 1, sd), 2), 
                             ")"))
    # res.mat2[k, 3:4] <- rowMeans(ise.cov)   # ISE
    # ise_sd[2, 3:4] <- apply(ise.cov, 1, sd)
  }
}

knitr::kable(res.mat, digits = 3, align = "r", caption = "Table 2. Average RMISE (standard error) of variances($\\hat{\\sigma}_X^2$) and covariances($\\hat{\\mathbf{C}}$) estimation.") %>% 
    kable_styling("striped", full_width = FALSE, font_size = 14) %>% 
    add_header_above(c(" " = 1, " " = 1, "$\\hat{\\sigma}_X^2$" = 2, "$\\hat{\\mathbf{C}}$" = 2))


knitr::kable(res.mat2, digits = 3, align = "r", caption = "Table 3. Average MISE (standard error) of covariance estimation between intrapolation($\\mathcal{D}_0$) and extrapolation($\\mathcal{S}_0 \\backslash \\mathcal{D}_0$) parts.") %>% 
    kable_styling("striped", full_width = FALSE, font_size = 14) %>% 
    add_header_above(c(" " = 1, " " = 1, "$\\mathcal{D}_0$" = 2, "$\\mathcal{S}_0 \\backslash \\mathcal{D}_0$" = 2))
```

```{r tab_Delaigle, out.width = "100%"}
file_name <- paste0(getwd(), "/ref/paper_tab_Delaigle.png")
knitr::include_graphics(file_name)
```


